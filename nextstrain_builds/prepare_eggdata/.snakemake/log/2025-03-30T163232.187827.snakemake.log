Building DAG of jobs...
Using shell: /Users/katekistler/.nextstrain/runtimes/conda/env/bin/bash
Provided cores: 8
Rules claiming more threads will be scaled down.
Job stats:
job                          count
-------------------------  -------
all                              1
combine_metadata                 1
combine_sequences                1
download_background_seqs         1
filter_egg_seqs                  1
parse_background_seqs            1
parse_egg_seqs                   1
prune_metadata                   1
subsample_background_seqs        1
total                            9

Select jobs to execute...

[Sun Mar 30 16:32:33 2025]
rule filter_egg_seqs:
    input: raw_data/h1n1pdm/ha/egg-passaged-sequences.fasta
    output: raw_data/h1n1pdm/ha/filtered-egg-passaged-sequences.fasta, include_exclude/h1n1pdm/ha/include.txt
    jobid: 3
    reason: Missing output files: include_exclude/h1n1pdm/ha/include.txt
    wildcards: lineage=h1n1pdm, segment=ha
    resources: tmpdir=/var/folders/g_/6938g_6s199gxxswt2nf7w500000gn/T


[Sun Mar 30 16:32:33 2025]
rule download_background_seqs:
    output: raw_data/h1n1pdm/ha/raw_background-sequences.fasta
    jobid: 8
    reason: Missing output files: raw_data/h1n1pdm/ha/raw_background-sequences.fasta
    wildcards: lineage=h1n1pdm, segment=ha
    resources: tmpdir=/var/folders/g_/6938g_6s199gxxswt2nf7w500000gn/T

[Sun Mar 30 16:32:33 2025]
Finished job 3.
1 of 9 steps (11%) done
Select jobs to execute...

[Sun Mar 30 16:32:33 2025]
rule parse_egg_seqs:
    input: raw_data/h1n1pdm/ha/filtered-egg-passaged-sequences.fasta, include_exclude/h1n1pdm/ha/include.txt
    output: parsed_data/h1n1pdm/ha/egg_sequences.fasta, parsed_data/h1n1pdm/ha/egg_metadata.tsv
    jobid: 2
    reason: Missing output files: parsed_data/h1n1pdm/ha/egg_sequences.fasta, parsed_data/h1n1pdm/ha/egg_metadata.tsv; Input files updated by another job: include_exclude/h1n1pdm/ha/include.txt, raw_data/h1n1pdm/ha/filtered-egg-passaged-sequences.fasta
    wildcards: lineage=h1n1pdm, segment=ha
    resources: tmpdir=/var/folders/g_/6938g_6s199gxxswt2nf7w500000gn/T

[Sun Mar 30 16:32:34 2025]
Error in rule parse_egg_seqs:
    jobid: 2
    input: raw_data/h1n1pdm/ha/filtered-egg-passaged-sequences.fasta, include_exclude/h1n1pdm/ha/include.txt
    output: parsed_data/h1n1pdm/ha/egg_sequences.fasta, parsed_data/h1n1pdm/ha/egg_metadata.tsv
    shell:
        
        augur parse             --sequences raw_data/h1n1pdm/ha/filtered-egg-passaged-sequences.fasta include_exclude/h1n1pdm/ha/include.txt             --output-sequences parsed_data/h1n1pdm/ha/egg_sequences.fasta             --output-metadata parsed_data/h1n1pdm/ha/egg_metadata.tsv             --fields strain virus lineage locus accession date date_submitted region country division location passage passage_category originating_lab submitting_lab age gender         
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

